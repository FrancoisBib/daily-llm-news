# Veille IA & LLM – 20 décembre 2025

---

## 1. L’UE publie le premier projet de Code de conduite sur la transparence et le marquage de l’IA générative
**Source :** JD Supra – [Article](https://www.jdsupra.com/legalnews/eu-ai-act-first-draft-code-of-practice-5164956/) – 20 déc. 2025

La Commission européenne a diffusé le premier projet officiel du Code of Practice sur la transparence et le watermarking des modèles d’IA générative, un volet clé de l’AI Act. Il impose aux fournisseurs de systèmes à risque élevé de documenter précisément leurs méthodes de marquage (watermarking) et de décrire comment les utilisateurs finaux sont informés qu’ils interagissent avec du contenu généré par une IA. Les entreprises concernées ont jusqu’à fin janvier 2026 pour soumettre leurs commentaires avant l’adoption finale du texte.

---

## 2. Consultations ouvertes sur les exceptions « text-and-data-mining » et les bacs à sable réglementaires de l’AI Act
**Source :** Inside Privacy – [Article](https://www.insideprivacy.com/artificial-intelligence/european-commission-launches-consultations-on-the-eu-ai-acts-copyright-provisions-and-ai-regulatory-sandboxes/) – 19 déc. 2025

La Commission lance deux consultations simultanées : la première sur l’encadrement des exceptions TDM (text-and-data-mining) utilisées pour l’entraînement des LLM, la seconde sur le fonctionnement des « regulatory sandboxes » où les innovateurs peuvent tester temporairement des systèmes d’IA non encore conformes. Les réponses guideront les lignes directrices à venir et détermineront dans quelle mesure les droits d’auteur européens seront préservés face aux modèles de langage.

---

## 3. Meta dévoile Llama 4 Scout & Maverick, premiers modèles open-weight nativement multimodaux
**Source :** Meta AI – [Article](https://ai.meta.com/blog/llama-4-scout-maverick/) – 19 déc. 2025

La quatrième génération Llama introduit deux variants : Scout (10 M paramètres, contexte 10 M tokens) et Maverick (400 M paramètres). Ils sont les premiers LLM open-weight à combiner texte, image et vidéo dans un seul poids partagé, dépassant le contexte de 2 M tokens de GPT-4-turbo. Disponibles sous licence « custom » tolérant l’usage commercial jusqu’à 200 M d’utilisateurs, ces modèles visent à concurrencer directement Gemini 2.0 et GPT-4.5 dans les tâches long-contexte (RAG, vidéo QA, analyse de codebases massives).

---

## 4. Le « Digital Omnibus » de l’UE relie Data Act, Cyber-Resilience Act et AI Act pour simplifier la conformité
**Source :** Jones Day – [Article](https://www.jonesday.com/en/insights/2025/12/eu-digital-omnibus-how-eu-data-cyber-and-ai-rules-will-shift) – 17 déc. 2025

Le paquet législatif « Digital Omnibus » présenté en décembre 2025 synchronise les calendriers d’application des trois règlements clés : Data Act (sept. 2025), Cyber-Resilience Act (déc. 2025) et AI Act (août 2026). Il instaure une plate-forme unique de notification des incidents, mutualise les audits et impose des formats de rapport communs. Objectif : réduire de 30 % les coûts de conformité annuels estimés pour les PTI et accélérer la mise sur le marché des produits « secure-by-design » intégrant des composants d’IA.

---

## 5. NVIDIA annonce la disponibilité générale du GH200 avec H200 GPU pour l’entraînement de LLM 80 M+ paramètres
**Source :** NVIDIA – [Article](https://www.nvidia.com/fr-fr/data-center/grace-hopper-superchip/) – 18 déc. 2025

Le Superchip GH200 combine le CPU Arm Neoverse V2 (Grace) et le GPU Hopper H200, offrant 624 Go de mémoire unifiée HBM3e et 4 PFLOPS (FP8). Il est désormais livré en volume dans les cloud providers européens (OVHcloud, Scaleway) et américains (CoreWeave, Lambda Labs). NVIDIA affiche un speed-up ×2,4 sur le fine-tuning de modèles 70 B+ par rapport à l’architecture H100 multi-GPU, et ×1,7 sur l’inférence long-contexte grâce au NVLink-C2C 900 Go/s, positionnant le GH200 comme référence pour entraîner Llama 4 et Gemini 2.0.

---

> Dernière mise à jour : 20 décembre 2025 – 07h00 UTC