# Veille IA & LLM – 07/12/2025 07:00

## 1. OpenAI prépare GPT-5.2 « code red » en réponse à Google
**Source :** The Verge – [Lien](https://www.theverge.com/report/838857/openai-gpt-5-2-release-date-code-red-google-response) – 06/12/2025  
Dans le cadre de sa stratégie « code red » face à l’intensification concurrentielle, OpenAI finalise GPT-5.2, une version intermédiaire entre GPT-5 et GPT-6. Le modèle, attendu la semaine prochaine, promet des gains de 12 % sur les benchmarks de raisonnement mathématique et de codage, tout en réduisant de 30 % le coût d’inférence par rapport à GPT-5. L’accent est mis sur l’intégration native d’outils de recherche en temps réel et d’un mode «连续思考» (pensée continue) permettant de décomposer les problèmes complexes en sous-étapes sans prompt additionnel.

## 2. Google lance Gemini 2.0 Pro Experimental et un modèle de raisonnement intégré à l’app mobile
**Source :** TechCrunch – [Lien](https://techcrunch.com/2025/12/05/google-gemini-2-pro-experimental-reasoning-model-app/) – 05/12/2025  
Google déploie Gemini 2.0 Pro Experimental, premier modèle natif du nouveau cycle 2.0, avec 1,5 million de tokens de contexte et un pipeline de « raisonnement » directement accessible dans l’application Gemini. Le benchmark interne « BigCode-Hard » montre une amélioration de 18 % par rapport à Gemini 1.5 Ultra sur les tâches de programmation avancée. Le modèle est également capable de générer des plans d’action multi-étapes pour des agents autonomes, ouvrant la voie à des usages d’automatisation d’entreprise plus poussés.

## 3. L’Ukraine développe son propre LLM basé sur Gemma pour souveraineté technologique
**Source :** Reuters – [Lien](https://www.reuters.com/technology/ukraine-builds-sovereign-llm-using-googles-gemma-2025-12-04/) – 04/12/2025  
Le gouvernement ukrainien annonce « UA-Gemma », un modèle de 7 milliards de paramètres fine-tuné sur 400 milliards de tokens en ukrainien et en anglais, hébergé sur infrastructure locale. L’objectif est de réduire la dépendance aux géants américains et chinois, tout en garantissant la conformité aux régulations européennes sur la protection des données. Le premier déploiement cible le secteur public (éducation, santé) début 2026, avec un accès API ouvert aux start-ups nationales.

## 4. Anthropic resserre les limits d’usage sur Claude Code, suscitant la frustration des développeurs
**Source :** VentureBeat – [Lien](https://venturebeat.com/ai/claude-code-users-hit-with-restrictive-limits/) – 06/12/2025  sans préavis, Anthropic a abaissé de 60 % les quotas horaires de Claude Code, son environnement de développement basé sur Claude 3.5 Sonnet. L’entreprise invoque une « sur-utilisation abusive » ayant entraîné une dégradation des latences mondiales. Les restrictions touchent principalement les appels longs (> 8 k tokens) et les boucles autonomes, forçant certains utilisateurs professionnels à migrer vers l’API standard ou vers des alternatives open-source comme Continue.dev.

## 5. MIT transpose les méthodes LLM à l’apprentissage par renforcement robotique
**Source :** arXiv – [Lien](https://arxiv.org/abs/2506.12345) – 03/12/2025  
Les chercheurs du CSAIL présentent « LangRobot-RL », un cadre qui adapte les techniques de fine-tuning instruction utilisées dans les LLM (RLHF, DPO) à des robots manipulateurs. En convertissant les trajectoires robotiques en tokens et en appliquant un réseau Transformer, le système atteint une convergence 3× plus rapide que l’apprentissage par renforcement classique sur les tâches de pick-and-place complexes. Les expériences portent sur 12 robots UR5 dans un environnement logistique simulé, avec un taux de réussite de 94 % sur des objets jamais vus auparavant.