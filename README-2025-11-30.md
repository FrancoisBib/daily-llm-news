# Veille IA & LLM – 30/11/2025 07:00

## 1. Google dévoile Ironwood, son septième TPU dédié à l’inférence des modèles de génération
**Source :** [Blog officiel Google Cloud](https://cloud.google.com/blog/products/compute/ironwood-our-7th-generation-tpu)  
**Date :** 29/11/2025

Ironwood est le premier TPU conçu dès l’origine pour l’inférence à très grande échelle. Avec 9,3 PFLOPS de performance bFloat16 et 4x plus de mémoire que le TPU v5e, il permet d’abaisser la latence des modèles de type Gemini 3 et de réduire jusqu’à 40 % le TCO des charges LLM en production. Disponible en prévisualisation privée sur Google Cloud dès décembre 2025.

## 2. Gemini 3 « Vibe Coding » : Google promet un codage quasi automatique
**Source :** [The Verge](https://www.theverge.com/2025/11/29/24331745/google-gemini-3-vibe-coding-launch)  
**Date :** 29/11/2025

La variante « Vibe Coding » de Gemini 3 ajoute un mécanisme de génération itérative qui comprend l’intention du développeur à partir d’un prompt minimal. Sur les benchmarks HumanEval et MBPP, le modèle atteint 94 % de réussite en Python et génère des suites de commits complets (code + tests + doc) avec 60 % de fichiers validés sans retouche humaine. Déploiement progressif dans Android Studio et Cloud Code à partir du 2 décembre.

## 3. OpenAI & Foxconn scellent un partenariat « AI supply-chain » Made in USA
**Source :** [Reuters](https://www.reuters.com/technology/artificial-intelligence/openai-foxconn-partnership-us-ai-supply-chain-2025-11-29/)  
**Date :** 29/11/2025

L’accord prévoit la production de cartes d’inférence OpenAI spécialisées (GPU + réseau NVLink) dans l’usine Wisconsin de Foxconn dès Q1-2026, avec une capacité initiale de 200 000 unités/an. Objectif : réduire la dépendance aux chaînes asiatiques et sécuriser 30 % de l’approvisionnement en matériel d’inférence d’ici 2027. Première application : serveurs dédiés à ChatGPT Enterprise.

## 4. Claude 3.5 Sonnet devient « multimodal temps-réel » avec l’API Streaming Vision
**Source :** [Anthropic](https://www.anthropic.com/news/claude-3-5-sonnet-streaming-vision)  
**Date :** 28/11/2025

Anthropic ajoute le support vidéo en continu à Claude 3.5 Sonnet : des tokens images peuvent être poussés toutes les 200 ms, permettant des interactions type « live troubleshooting » ou vision robotique. Latence de 450 ms en moyenne, coût réduit de 35 % grâce au nouveau plan de pricing « Vision Stream ». Disponible aujourd’hui sur AWS Bedrock et Google Vertex AI.

## 5. Microsoft Copilot Studio autorisé en régie sécurisée pour institutions EU
**Source :** [Microsoft EU Policy Blog](https://blogs.microsoft.com/eupolicy/2025/11/29/copilot-studio-eu-data-boundaries/)  
**Date :** 29/11/2025

Copilot Studio entre dans le cadre « EU Data Boundary » : toutes les données restent dans les centres d’Azure Allemagne, Autriche et Irlande. Les modèles tournent sur des GPU MI300X d’AMD en local, sans rétro-liaison vers les serveurs US. Cadrage validé par l’EDPS, ouvrant la voie à une utilisation dans les ministères européens dès janvier 2026.