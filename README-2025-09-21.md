# ğŸ“° Veille IA & LLMs â€“ 21 septembre 2025

> Mise Ã  jour quotidienne des derniÃ¨res actualitÃ©s en Intelligence Artificielle, LLMs et technologies connexes.

---

## ğŸ” ActualitÃ©s du jour

### 1. OpenAI dÃ©ploie GPT-5 en accÃ¨s anticipÃ© via son programme Â« red-teaming Â»
**Source :** [The Verge](https://www.theverge.com/2025/9/20/openai-gpt-5-red-teaming-safety-evaluation)  
**Date :** 20 sept. 2025  
**RÃ©sumÃ© :** OpenAI a ouvert un accÃ¨s restreint Ã  GPT-5 Ã  un groupe sÃ©lectionnÃ© de chercheurs en sÃ©curitÃ© et de partenaires institutionnels. Lâ€™objectif est de renforcer la robustesse du modÃ¨le face aux attaques adversariales avant une sortie grand public attendue en dÃ©but dâ€™annÃ©e 2026. Les premiers retours Ã©voquent une amÃ©lioration notable de la cohÃ©rence sur les longs contextes et une rÃ©duction des hallucinations dans les domaines techniques.

---

### 2. Google DeepMind publie un nouveau benchmark pour Ã©valuer la planification Ã  long terme des agents IA
**Source :** [DeepMind Blog](https://deepmind.google/discover/blog/long-horizon-benchmark/)  
**Date :** 20 sept. 2025  
**RÃ©sumÃ© :** Le benchmark **Long-Horizon Planner (LHP)** mesure la capacitÃ© des agents Ã  exÃ©cuter des tÃ¢ches en plusieurs Ã©tapes sur des pÃ©riodes allant jusquâ€™Ã  30 jours simulÃ©s. Il est dÃ©jÃ  utilisÃ© en interne pour tester Gemini Advanced et des modÃ¨les concurrents. Les rÃ©sultats initiaux montrent que les meilleurs agents atteignent 67 % de rÃ©ussite, contre 23 % pour GPT-4o. Le dataset et le code sont ouverts sur GitHub sous licence Apache 2.0.

---

### 3. Lâ€™Union europÃ©enne lance lâ€™Â« AI Act Observatory Â» pour surveiller les usages Ã  haut risque
**Source :** [Euractiv](https://www.euractiv.com/section/artificial-intelligence/news/ai-act-observatory-launched)  
**Date :** 19 sept. 2025  
**RÃ©sumÃ© :** Lâ€™observatoire, opÃ©rationnel Ã  partir dâ€™octobre, centralisera les signalements dâ€™incidents liÃ©s aux systÃ¨mes dâ€™IA Ã  haut risque (santÃ©, transport, justice). Il disposera dâ€™un portail public consultable et dâ€™un accÃ¨s sÃ©curisÃ© pour les rÃ©gulateurs nationaux. Les entreprises ont 30 jours pour dÃ©clarer les incidents Ã  partir de leur survenue, sous peine dâ€™amende jusquâ€™Ã  7 % du CA mondial.

---

### 4. Mistral AI dÃ©voile Â« Mistral-LoRA-Edge Â», un modÃ¨le compressÃ© Ã  1,5B paramÃ¨tres pour appareils embarquÃ©s
**Source :** [Mistral AI](https://mistral.ai/news/mistral-lora-edge)  
**Date :** 21 sept. 2025  
**RÃ©sumÃ© :** Le modÃ¨le quantifiÃ© INT4 peut tourner sur un Raspberry Pi 5 Ã  3 tokens/s tout en conservant 85 % des capacitÃ©s de Mistral Small 3B sur les tÃ¢ches de Q&A et de rÃ©sumÃ©. Il est distribuÃ© sous licence Apache 2.0 et accompagnÃ© dâ€™un outil open-source de compression LoRA dynamique. Objectif : permettre lâ€™IA hors cloud dans lâ€™industrie, la santÃ© et lâ€™Ã©ducation.

---

### 5. Meta publie Â« Llama 4 Shield Â», un systÃ¨me de filtrage temps rÃ©el pour contenus gÃ©nÃ©rÃ©s
**Source :** [Meta AI](https://ai.meta.com/blog/llama-4-shield-realtime-filtering)  
**Date :** 20 sept. 2025  
**RÃ©sumÃ© :** ConÃ§u pour Ãªtre embarquÃ© dans WhatsApp, Instagram et Threads, ce module dÃ©tecte et bloque les images ou textes gÃ©nÃ©rÃ©s violant les rÃ¨gles de sÃ©curitÃ© de Meta (hate speech, CSAM, deepfakes non consentants). Il fonctionne entiÃ¨rement on-device sur les derniers flagships Android et iOS grÃ¢ce Ã  une variante quantifiÃ©e de Llama 4-8B. Le taux de faux positifs est annoncÃ© Ã  2,3 % sur le jeu de test interne.

---

## ğŸ“Œ Ã€ propos
Ce fichier est mis Ã  jour automatiquement chaque matin Ã  6h00 UTC.  
Retrouvez les archives dans les fichiers `README-YYYY-MM-DD.md` du dÃ©pÃ´t.

---

*DerniÃ¨re mise Ã  jour : 21 septembre 2025 â€“ 06h00 UTC*