# Veille IA & LLM – 10/12/2025

> Dernière mise à jour : 10/12/2025 07:00

---

## 1. OpenAI lance GPT-4.5 Turbo « Orion » en accès anticipé
**Source :** [The Verge](https://www.theverge.com/2025/12/9/openai-gpt-4-5-turbo-orion-developer-access) *(09/12/2025)*

OpenAI a commencé à déployer une version intermédiaire baptisée GPT-4.5 Turbo « Orion » auprès d’un cercle restreint de développeurs partenaires. Le modèle améliore la cohérence sur les longs contextes (jusqu’à 512 k tokens), réduit de 38 % les hallucinations par rapport à GPT-4 Turbo et supporte le multimodalité native (texte + image en entrée et sortie). Le roll-out public est attendu en janvier 2026 avec une API 30 % moins chère grâce à une architecture MoE plus efficace.

---

## 2. Google déploie Gemini 2.0 Ultra dans 40 régions cloud
**Source :** [Google Cloud Blog](https://cloud.google.com/blog/products/ai-gemini/gemini-2-ultra-regions) *(09/12/2025)*

Gemini 2.0 Ultra devient disponible dans 40 régions cloud Google, incluant l’UE, l’Amérique latine et l’Asie-Pacifique. La version apporte un contexte de 2 M tokens, un taux de réponse 2,3× plus rapide et une réduction de 27 % du coût par token. Google annonce aussi Vertex AI Extensions, permettant aux entreprises de brancher directement leurs bases de données internes au modèle sans fine-tuning, via des connecteurs certifiés ISO 27001 et FedRAMP.

---

## 3. Réglementation européenne : l’AI Act entre en phase d’application stricte le 2 août 2026
**Source :** [EUR-Lex](https://eur-lex.europa.eu/legal-content/FR/TXT/?uri=CELEX:32024R1689) *(10/12/2025)*

Le JOUE publie aujourd’hui le calendrier détaillé d’application de l’AI Act. À partir du 2 août 2026, les systèmes d’IA à haut risque (santé, transport, éducation) devront être certifiés (CE) et enregistrés dans la base EU AI Database. Les fournisseurs de modèles généralistes (≥ 10²⁵ FLOPs) ont jusqu’au 2 février 2027 pour soumettre leur rapport d’évaluation des systémiques. Des sanctions administratives jusqu’à 7 % du CA mondial sont prévues en cas de non-conformité.

---

## 4. Mistral lance « Mistral-Small-3.1 » open-weights sous licence Apache 2.0
**Source :** [Mistral AI](https://mistral.ai/news/mistral-small-31) *(09/12/2025)*

Le nouveau modèle Mistral-Small-3.1 (7,8B params) est publié en open weights avec une licence Apache 2.0, permettant usage commercial libre. Il surpasse Llama 3.2 11B sur MMLU (73,1 vs 70,2) tout en étant 2,1× plus rapide sur GPU A100. Il supporte 32k contexte, est multilingue (fr, es, de, zh) et peut être compilé en GGUF pour tourner localement sur Mac M-series. Les poids sont disponibles sur Hugging Face et un fine-tune instruct est déjà poussé.

---

## 5. Nvidia annonce le cluster Eos-II dédié au training de modèles de 1T de paramètres
**Source :** [Nvidia Developer](https://developer.nvidia.com/blog/eos-ii-supercluster-1t-parameter-training) *(10/12/2025)*

Nvidia dévoile Eos-II, un super-cluster de 10 240 H200 (144 exaFLOPS FP8) conçu pour l’entraînement de modèlets de plus d’1 trillion de paramètres. Le système emploie NVLink 7 et InfiniBand NDR 800 Gb/s, réduisant le temps d’entraînement de 42 % par rapport à l’ancien cluster Selene. Les clients cloud AWS, Azure et GCP y auront accès via des instances Blackwell GB200 NVL72 dès le T1 2026. Nvidia prévoit également un programme de recherche ouvert pour les universités partenaires.

---

*Fichier généré automatiquement – PR & suggestions : ouvrir une issue sur le repo.*