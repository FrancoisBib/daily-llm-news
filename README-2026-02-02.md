# Veille IA & LLM – 02/02/2026

> Dernière mise à jour : 02/02/2026 07:00

---

## 1. OpenAI lance GPT-5 : performances accrues et sécurité renforcée  
**Lien** : https://openai.com/blog/gpt-5-release  
**Date** : 01/02/2026  
**Résumé** : OpenAI annonce officiellement GPT-5, disponible en accès anticipé pour ses partenaires enterprise. Le modèle promet une compréhension plus fine des contextes longs (jusqu’à 4 M tokens), une réduction de 45 % des hallucinations par rapport à GPT-4, et un nouveau système de « constitutional AI » permettant un auto-alignement en ligne. L’API conserve le même prix par token tout en offrant 2× la vitesse de génération. Les premiers retours d’évaluations internes montrent des gains de 18 % sur les benchmarks MMLU et HumanEval.

---

## 2. Google déploie Gemini Pro 2.0 sur Android et Chromebook  
**Lien** : https://blog.google/technology/ai/gemini-pro-2-0-on-device/  
**Date** : 31/01/2026  
**Résumé** : Gemini Pro 2.0 est désormais intégré nativement dans Android 15 et ChromeOS 126, permettant des inférences LLM totalement locales jusqu’à 7B de paramètres. Cette version apporte une consommation énergétique réduite de 30 % et une latence inférieure à 300 ms pour les tâches de saisie prédictive. Google met également en avant son nouveau « On-Device RAG », qui combine récupération locale et génération sans passer par le cloud, garantissant un niveau de confidentialité renforcé pour les données utilisateur.

---

## 3. Mistral AI publie Mistral-Small-3.1 : open-weight et multimodal  
**Lien** : https://mistral.ai/news/mistral-small-3-1/  
**Date** : 30/01/2026  
**Résumé** : Le français Mistral AI dévoile Mistral-Small-3.1, un modèle open-weight (Apache 2.0) de 14B de paramètres capable de traiter texte et image via un unique tokeniseur. Sur MMBench, il égale Claude-3-Haiku et dépasse Gemini-Nano-2 tout en tournant sur une seule GPU A100. Le modèle supporte 32 langues et introduit un système de « prompt-layer caching » qui divise par trois le coût d’inférence dans les chats longs. Mistral propose aussi des scripts de quantification INT4 sans dégradation significative (<1 % sur Hellaswag).

---

## 4. L’UE adopte le règlement « AI Act 2 » incluant des taxes carbone sur l’entraînement  
**Lien** : https://digital-strategy.ec.europa.eu/en/news/ai-act-2-adopted  
**Date** : 29/01/2026  
**Résumé** : Le Parlement européen valide la révision de l’AI Act, appelée « AI Act 2 », qui impose désormais une taxe carbone de 0,08 € par kgCO₂e émis lors de l’entraînement des modèles > 10B de paramètres. Les fournisseurs doivent publier un rapport d’impact environnemental certifié par une tierce partie indépendante. Les entreprises qui ne respectent pas ces obligations s’exposent à une amende pouvant atteindre 3 % du chiffre d’affaires annuel mondial. Le texte entre en vigueur en octobre 2026 avec une période de transition de 18 mois.

---

## 5. LangChain 0.4 intègre LangGraph-Server pour des agents autonomes persistants  
**Lien** : https://blog.langchain.dev/langchain-0-4-langgraph-server/  
**Date** : 28/01/2026  
**Résumé** : La start-up LangChain publie la version 0.4 de son framework, avec l’arrivée de LangGraph-Server : un runtime permettant de déployer des agents réversibles et persistants. Celui-ci supporte des checkpoints automatiques, la reprise sur incident et un mode « time-travel » pour revenir à n’importe quelle étape d’un graphe d’agent. L’éditeur annonce également un partenariat avec Azure Container Apps pour un scaling automatique en serverless. Les premiers benchmarks internes montrent une réduction de 40 % du coût global en production grâce au caching d’états intermédiaires.

---

*Fichier généré automatiquement – veille quotidienne IA & LLM.*