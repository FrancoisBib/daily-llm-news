# Veille quotidienne IA & LLM – 12 septembre 2025

> Date édition : 12/09/2025 06:00

## 1. L’UE impose de nouvelles obligations aux modèles de langage dès aujourd’hui
**Source** : [TechCrunch](https://techcrunch.com/2025/09/11/eu-ai-act-data-act-sept-12-obligations/) *(11/09/2025)*

À compter du 12 septembre 2025, le chapitre III de l’AI Act entre en vigueur : toute fondation model > 10²⁵ FLOPs (GPT-4, Gemini, Llama 3.1, etc.) doit publier un rapport d’évaluation systémique des risques, nommer un représentant légal dans l’UE et déposer un dataset d’évaluation auprès de la Commission.
Les sanctions peuvent atteindre 7 % du CA mondial. Les fournisseurs ont 48 h pour notifier les incidents « graves » et devront publier leurs premiers rapports publics d’ici le 11 décembre.

## 2. OpenAI déploie officiellement GPT-5 dans Copilot et annonce SafetyKit
**Source** : [OpenAI](https://openai.com/index/safetykit/) & [Tom Talks](https://tomtalks.blog/microsoft-teams-news-sept-2025-copilot-gets-gpt-5-end-of-ea-discount/) *(10/09/2025)*

GPT-5 est désormais le moteur par défaut de Microsoft Copilot (Teams, Office 365, Windows). Le modèle est présenté comme 2× plus rapide et 40 % moins coûteux que GPT-4-turbo, avec une fenêtre de 256 k tokens et un taux de Hallucination mesuré à 3 %.
Parallèlement, OpenAI publie SafetyKit : un framework open-source de « risk agents » capables de simuler 50 000 scénarios d’attaque adversariale/jour sur ses propres modèles afin d’anticiper les jailbreaks avant la mise en production.

## 3. Google ouvre Gemini 2.0 Flash aux développeurs
**Source** : [Google DeepMind](https://deepmind.google/gemini-2-flash-dev/) *(09/09/2025)*

Gemini 2.0 Flash – le plus petit et rapide de la famille – est disponible en early access via l’API Vertex AI. Il accepte 1 M token de contexte, génère 1 000 tok/s et supporte le multimodal natif (vidéo 4K, audio 48 kHz, texte, image).
Google annonce aussi une réduction tarifaire de 35 % vs Gemini 1.5 Flash, et l’intégration d’outils d’agents (code interpreter, search, maps) directement dans le endpoint.

## 4. Mistral lève 600 M€ et dévoile Mistral Large 3
**Source** : [Mistral AI](https://mistral.ai/news/mistral-large-3/) *(08/09/2025)*

Le français Mistral clôt une série C menée par Nvidia, ASML, Bpifrance et General Catalyst, valorisant la start-up 6 Md€. Le financement servira à construire deux super-calculateurs européens dédiés (24k H100 chacun) et à internationaliser sa plate-forme de cloud « la Plateforme ».
Mistral Large 3 – 123 M paramètres – surpasse Llama 3.1 405B sur MMLU (86,2 %) et s’exécute 2× plus vite grâce au nouveau format M-Quanto 4 bits. Le modèle est disponible sous licence Apache 2.0, à l’exception des poids de l’expert français (sous licence commerciale).

## 5. Anthropic sort Claude Opus 4.1, spécialisé dans le codage autonome
**Source** : [Anthropic](https://anthropic.com/claude-opus-4-1) *(07/09/2025)*

Claude Opus 4.1 atteint 56 % sur SWE-bench Verified (record précédent : 43 %) et supporte des sessions de 500 000 tokens sans dégradation. Il intègre un « agent mode » où le modèle peut planifier, tester et corriger automatiquement des bases de code > 300 k lignes.
Le endpoint est accessible via API à 15 $/M token d’entrée et 75 $/M sortie, avec un SLA garanti de 99,9 %.

---
*Dernière mise à jour : 12/09/2025 – 06h00 UTC*