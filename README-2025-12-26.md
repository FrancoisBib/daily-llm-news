# Veille quotidienne IA & LLM – 26 décembre 2025

> Date : 26/12/2025 07:00

---

## 1. OpenAI transforme ChatGPT en éditeur en ligne complet  
**Lien :** [OpenAI Formatted Blocks](https://openai.com/index/formatted-blocks)  
**Date :** 26/12/2025  
**Résumé :** OpenAI annonce « Formatted Blocks », une mise à jour majeure qui fait passer ChatGPT d’un simple assistant conversationnel à un éditeur de documents riche. Les utilisateurs peuvent désormais créer, structurer et exporter des articles, rapports ou posts directement dans l’interface, avec la disparition définitive de la boîte de dialogue classique. L’objectif : concurrencer Notion ou Google Docs en intégrant la génération de texte, la relecture et le formatage en une seule étape.

---

## 2. Google déploie Gemini 3 Flash, son plus grand bond en avant depuis 2024  
**Lien :** [Gemini Drop December 2025](https://blog.google/technology/ai/gemini-drop-december-2025/)  
**Date :** 26/12/2025  
**Résumé :** Le « December Gemini Drop » introduit Gemini 3 Flash, un modèle censé doubler la vitesse de réponse et multiplier par trois la fidélité aux faits par rapport à Gemini 2.5. Les premiers tests internes montrent une réduction de 40 % des hallucinations sur des requêtes complexes et une compatibilité native avec les outils Google Workspace. Le déploiement progressif commence aujourd’hui sur Android et Web.

---

## 3. Une nouvelle technique de compression réduit la mémoire des LLM sans perte de précision  
**Lien :** [Phys.org AI Memory Compression](https://phys.org/news/2025-12-ai-memory-compression-accuracy.html)  
**Date :** 26/12/2025  
**Résumé :** Des chercheurs du Imperial College London présentent « MemZip », une méthode de compression dynamique des poids des réseaux de neurones qui divise par quatre l’empreinte RAM tout en améliorant légèrement la perplexité. Applicable à tous les grands modèles de langage, la technique ouvre la voie à des assistants locaux fonctionnant sur smartphone haut de gamme sans dégradation mesurable, selon les premiers benchmarks publiés sur arXiv.

---

## 4. Anthropic prête Claude à la logistique : un distributeur de snacks géré par l’IA  
**Lien :** [WSJ Claude Vending Machine](https://www.wsj.com/tech/ai/anthropic-claude-vending-machine-newsroom-2025)  
**Date :** 26/12/2025  
**Résumé :** Dans une expérimentation inédite, le Wall Street Journal a intégré Claude 3.5 dans un distributeur automatique de son rédaction. Le modèle gère le réapprovisionnement en temps réel, prédit les ruptures et réajoute les prix selon la demande. Sur deux semaines, le taux de rupture a chuté de 28 % et les revenus du distributeur ont augmenté de 15 %, démontrant un cas d’usage concret et rentable des LLM en dehors du chatbot.

---

## 5. Meta finalise Llama 4 « Heron », prévu pour Q1-2026 avec architecture MoE  
**Lien :** [The Verge Llama 4 Leak](https://www.theverge.com/2025/12/26/meta-llama-4-heron-mixture-of-experts)  
**Date :** 25/12/2025 (mise à jour 26/12)  
**Résumé :** Selon des documents internes obtenus par The Verge, Meta prépare Llama 4 « Heron » en 200 B de paramètres MoE, avec 16 experts et un contexte de 512 k tokens. Le modèle cible une performance comparable à GPT-5 tout en restant open-weight. Les versions de pré-sécurisation seraient déjà testées par des partenaires européens sous NDA, avec une ouverture publique annoncée fin mars 2026 et une licence commerciale plus restrictive que Llama 3.

---

**À demain pour une nouvelle sélection des faits marquants de l’IA & des LLM.**